{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51941f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/itf-fi-ml/home/arunps/Projects/speaker-type-classifier/notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92a409c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")  # Navigate to project root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cff1ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/itf-fi-ml/home/arunps/Projects/speaker-type-classifier'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6db54f6",
   "metadata": {},
   "source": [
    "### Paths + HF cache on scratch + v1 folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9952e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET_VERSION: v1\n",
      "RAW_DIR: /scratch/users/arunps/speaker-type-classifier/data_hf/raw/v1\n",
      "EXPORT_DIR: /scratch/users/arunps/speaker-type-classifier/data_hf/export/v1\n",
      "MANIFEST_DIR: /scratch/users/arunps/speaker-type-classifier/data_hf/manifest/v1\n",
      "HF_HOME: /scratch/users/arunps/.cache/huggingface\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "SCRATCH = Path(\"/scratch/users/arunps\")\n",
    "PROJECT = \"speaker-type-classifier\"\n",
    "DATASET_VERSION = \"v1\"\n",
    "\n",
    "DATA_ROOT    = SCRATCH / PROJECT / \"data_hf\"\n",
    "RAW_DIR      = DATA_ROOT / \"raw\" / DATASET_VERSION\n",
    "EXPORT_DIR   = DATA_ROOT / \"export\" / DATASET_VERSION\n",
    "MANIFEST_DIR = DATA_ROOT / \"manifest\" / DATASET_VERSION\n",
    "REPORTS_DIR  = DATA_ROOT / \"reports\" / DATASET_VERSION\n",
    "\n",
    "for p in [RAW_DIR, EXPORT_DIR, MANIFEST_DIR, REPORTS_DIR]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# HF cache to scratch (avoid filling $HOME)\n",
    "os.environ[\"HF_HOME\"] = str(SCRATCH / \".cache\" / \"huggingface\")\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = str(SCRATCH / \".cache\" / \"huggingface\" / \"datasets\")\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = str(SCRATCH / \".cache\" / \"huggingface\" / \"transformers\")\n",
    "\n",
    "# Create export class folders\n",
    "CLASS_DIRS = {\n",
    "    \"adult_male\": EXPORT_DIR / \"adult_male\",\n",
    "    \"adult_female\": EXPORT_DIR / \"adult_female\",\n",
    "    \"child\": EXPORT_DIR / \"child\",\n",
    "    \"background\": EXPORT_DIR / \"background\",\n",
    "}\n",
    "for d in CLASS_DIRS.values():\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"DATASET_VERSION:\", DATASET_VERSION)\n",
    "print(\"RAW_DIR:\", RAW_DIR)\n",
    "print(\"EXPORT_DIR:\", EXPORT_DIR)\n",
    "print(\"MANIFEST_DIR:\", MANIFEST_DIR)\n",
    "print(\"HF_HOME:\", os.environ[\"HF_HOME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8fe330d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in to Hugging Face Hub\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "load_dotenv()  \n",
    "\n",
    "login(token=os.getenv(\"HF_TOKEN\"))\n",
    "print(\"Logged in to Hugging Face Hub\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a79c7be",
   "metadata": {},
   "source": [
    "### Create unified class folders for v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e777afe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adult_male': PosixPath('/scratch/users/arunps/speaker-type-classifier/data_hf/export/v1/adult_male'),\n",
       " 'adult_female': PosixPath('/scratch/users/arunps/speaker-type-classifier/data_hf/export/v1/adult_female'),\n",
       " 'child': PosixPath('/scratch/users/arunps/speaker-type-classifier/data_hf/export/v1/child'),\n",
       " 'background': PosixPath('/scratch/users/arunps/speaker-type-classifier/data_hf/export/v1/background')}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "class_dirs = {\n",
    "    \"adult_male\": EXPORT_DIR / \"adult_male\",\n",
    "    \"adult_female\": EXPORT_DIR / \"adult_female\",\n",
    "    \"child\": EXPORT_DIR / \"child\",\n",
    "    \"background\": EXPORT_DIR / \"background\",\n",
    "}\n",
    "for d in class_dirs.values():\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "class_dirs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6b1311",
   "metadata": {},
   "source": [
    "### Audio write helper: mono + 16kHz WAV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00a3c66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "\n",
    "TARGET_SR = 16000\n",
    "\n",
    "def to_mono(x: np.ndarray) -> np.ndarray:\n",
    "    if x.ndim == 1:\n",
    "        return x\n",
    "    # average channels\n",
    "    return x.mean(axis=1) if x.shape[1] > 1 else x[:, 0]\n",
    "\n",
    "def normalize_and_write_wav(out_path, audio_np, sr):\n",
    "    audio_np = np.asarray(audio_np)\n",
    "    audio_np = to_mono(audio_np)\n",
    "\n",
    "    if sr != TARGET_SR:\n",
    "        audio_np = librosa.resample(audio_np, orig_sr=sr, target_sr=TARGET_SR)\n",
    "\n",
    "    sf.write(str(out_path), audio_np, TARGET_SR)\n",
    "    return out_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d1bcd9",
   "metadata": {},
   "source": [
    "### Generic inspector helpers (configs, splits, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7759a695",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import get_dataset_config_names, load_dataset_builder\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "def inspect_hf_dataset(repo_id: str, max_configs: int = 5):\n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(\"DATASET:\", repo_id)\n",
    "\n",
    "    # 1) configs\n",
    "    try:\n",
    "        configs = get_dataset_config_names(repo_id)\n",
    "    except Exception as e:\n",
    "        configs = []\n",
    "        print(\"Could not fetch config names:\", repr(e))\n",
    "\n",
    "    if configs:\n",
    "        print(f\"Configs ({len(configs)}):\", configs[:max_configs], (\"...\" if len(configs)>max_configs else \"\"))\n",
    "    else:\n",
    "        print(\"Configs: (none / default)\")\n",
    "\n",
    "    # 2) builder info for configs (splits + features)\n",
    "    cfgs_to_check = configs[:max_configs] if configs else [None]\n",
    "    for cfg in cfgs_to_check:\n",
    "        try:\n",
    "            b = load_dataset_builder(repo_id, cfg) if cfg else load_dataset_builder(repo_id)\n",
    "            splits = list(b.info.splits.keys()) if b.info.splits else []\n",
    "            print(\"\\n--- Config:\", cfg if cfg else \"(default)\")\n",
    "            print(\"Splits:\", splits)\n",
    "\n",
    "            # features/columns\n",
    "            feats = b.info.features\n",
    "            if feats is None:\n",
    "                print(\"Features: None\")\n",
    "            else:\n",
    "                print(\"Columns/features:\")\n",
    "                for k, v in feats.items():\n",
    "                    print(f\"  - {k}: {v}\")\n",
    "        except Exception as e:\n",
    "            print(\"\\n--- Config:\", cfg if cfg else \"(default)\")\n",
    "            print(\"Builder inspection failed:\", repr(e))\n",
    "\n",
    "\n",
    "def inspect_repo_files(repo_id: str, repo_type: str = \"dataset\", max_files: int = 40):\n",
    "    \"\"\"Useful for datasets that are basically files/shards (like WDS tar shards).\"\"\"\n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(\"REPO FILE LIST:\", repo_id)\n",
    "    api = HfApi()\n",
    "    files = api.list_repo_files(repo_id=repo_id, repo_type=repo_type)\n",
    "    print(f\"Total files: {len(files)}\")\n",
    "    for f in files[:max_files]:\n",
    "        print(\" \", f)\n",
    "    if len(files) > max_files:\n",
    "        print(\" ...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d3c5a1",
   "metadata": {},
   "source": [
    "### Inspect Vaani (columns + splits + configs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ae8a564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================================================\n",
      "DATASET: ARTPARK-IISc/Vaani\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d98bf6105b50405c8ccceed8daefd967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configs (170): ['AndhraPradesh_Anantpur', 'AndhraPradesh_Annamaya', 'AndhraPradesh_Chittoor', 'AndhraPradesh_Guntur', 'AndhraPradesh_Krishna', 'AndhraPradesh_Manyam', 'AndhraPradesh_SriSatyaSai', 'AndhraPradesh_Srikakulam', 'AndhraPradesh_Vishakapattanam', 'ArunachalPradesh_Longding'] ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e11c0c019ad4d02b00bc49bb1495741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58c2f8c469164d649abd6ab58852514b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Config: AndhraPradesh_Anantpur\n",
      "Splits: ['train']\n",
      "Columns/features:\n",
      "  - audio: Audio(sampling_rate=None, decode=True, num_channels=None, stream_index=None)\n",
      "  - language: Value('string')\n",
      "  - speakerID: Value('float64')\n",
      "  - languagesKnown: Value('string')\n",
      "  - gender: Value('string')\n",
      "  - state: Value('string')\n",
      "  - district: Value('string')\n",
      "  - pincode: Value('int64')\n",
      "  - stay(years): Value('string')\n",
      "  - isTranscriptionAvailable: Value('string')\n",
      "  - transcript: Value('string')\n",
      "  - referenceImage: Value('string')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d3051b155bc40f789527ef6581a8994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "353ba66f05f14f80b069fd43840f678c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Config: AndhraPradesh_Annamaya\n",
      "Splits: ['train']\n",
      "Columns/features:\n",
      "  - audio: Audio(sampling_rate=None, decode=True, num_channels=None, stream_index=None)\n",
      "  - language: Value('string')\n",
      "  - speakerID: Value('float64')\n",
      "  - languagesKnown: Value('string')\n",
      "  - gender: Value('string')\n",
      "  - state: Value('string')\n",
      "  - district: Value('string')\n",
      "  - pincode: Value('int64')\n",
      "  - stay(years): Value('string')\n",
      "  - isTranscriptionAvailable: Value('string')\n",
      "  - transcript: Value('string')\n",
      "  - referenceImage: Value('string')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f96f0b2a0954583b2777e75f21f6a7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f13a9fd5e2474f71bb8fda8908be1621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Config: AndhraPradesh_Chittoor\n",
      "Splits: ['train']\n",
      "Columns/features:\n",
      "  - audio: Audio(sampling_rate=None, decode=True, num_channels=None, stream_index=None)\n",
      "  - language: Value('string')\n",
      "  - speakerID: Value('float64')\n",
      "  - languagesKnown: Value('string')\n",
      "  - gender: Value('string')\n",
      "  - state: Value('string')\n",
      "  - district: Value('string')\n",
      "  - pincode: Value('int64')\n",
      "  - stay(years): Value('string')\n",
      "  - isTranscriptionAvailable: Value('string')\n",
      "  - transcript: Value('string')\n",
      "  - referenceImage: Value('string')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "149bf7331c004a9b8d18938c5b6c1f20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "580cd049751947adae541dbc0f9f86b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Config: AndhraPradesh_Guntur\n",
      "Splits: ['train']\n",
      "Columns/features:\n",
      "  - audio: Audio(sampling_rate=None, decode=True, num_channels=None, stream_index=None)\n",
      "  - language: Value('string')\n",
      "  - speakerID: Value('float64')\n",
      "  - languagesKnown: Value('string')\n",
      "  - gender: Value('string')\n",
      "  - state: Value('string')\n",
      "  - district: Value('string')\n",
      "  - pincode: Value('int64')\n",
      "  - stay(years): Value('string')\n",
      "  - isTranscriptionAvailable: Value('string')\n",
      "  - transcript: Value('string')\n",
      "  - referenceImage: Value('string')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b90751268534d5199a995235bc323c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3230755d68244d27b8b1fa71d3f860a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Config: AndhraPradesh_Krishna\n",
      "Splits: ['train']\n",
      "Columns/features:\n",
      "  - audio: Audio(sampling_rate=None, decode=True, num_channels=None, stream_index=None)\n",
      "  - language: Value('string')\n",
      "  - speakerID: Value('float64')\n",
      "  - languagesKnown: Value('string')\n",
      "  - gender: Value('string')\n",
      "  - state: Value('string')\n",
      "  - district: Value('string')\n",
      "  - pincode: Value('int64')\n",
      "  - stay(years): Value('string')\n",
      "  - isTranscriptionAvailable: Value('string')\n",
      "  - transcript: Value('string')\n",
      "  - referenceImage: Value('string')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df43f439420e46e9b96a3e4c3140a12c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Config: AndhraPradesh_Manyam\n",
      "Splits: ['train']\n",
      "Columns/features:\n",
      "  - audio: Audio(sampling_rate=None, decode=True, num_channels=None, stream_index=None)\n",
      "  - language: Value('string')\n",
      "  - speakerID: Value('float64')\n",
      "  - languagesKnown: Value('string')\n",
      "  - gender: Value('string')\n",
      "  - state: Value('string')\n",
      "  - district: Value('string')\n",
      "  - pincode: Value('int64')\n",
      "  - stay(years): Value('string')\n",
      "  - isTranscriptionAvailable: Value('string')\n",
      "  - transcript: Value('string')\n",
      "  - referenceImage: Value('string')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e74ddca668c6457c8322888ca5ab11e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a79df52f138e4123bc36890612e3b984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Config: AndhraPradesh_SriSatyaSai\n",
      "Splits: ['train']\n",
      "Columns/features:\n",
      "  - audio: Audio(sampling_rate=None, decode=True, num_channels=None, stream_index=None)\n",
      "  - language: Value('string')\n",
      "  - speakerID: Value('float64')\n",
      "  - languagesKnown: Value('string')\n",
      "  - gender: Value('string')\n",
      "  - state: Value('string')\n",
      "  - district: Value('string')\n",
      "  - pincode: Value('int64')\n",
      "  - stay(years): Value('string')\n",
      "  - isTranscriptionAvailable: Value('string')\n",
      "  - transcript: Value('string')\n",
      "  - referenceImage: Value('string')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a18ae0bdbe924eec8439ee5ad3cdb378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4ae0a7537b24751a38ff3186542f9f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Config: AndhraPradesh_Srikakulam\n",
      "Splits: ['train']\n",
      "Columns/features:\n",
      "  - audio: Audio(sampling_rate=None, decode=True, num_channels=None, stream_index=None)\n",
      "  - language: Value('string')\n",
      "  - speakerID: Value('float64')\n",
      "  - languagesKnown: Value('string')\n",
      "  - gender: Value('string')\n",
      "  - state: Value('string')\n",
      "  - district: Value('string')\n",
      "  - pincode: Value('int64')\n",
      "  - stay(years): Value('string')\n",
      "  - isTranscriptionAvailable: Value('string')\n",
      "  - transcript: Value('string')\n",
      "  - referenceImage: Value('string')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "856b081cdca648039936de6584095066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9e1994b2d9c48ec8cd0754a5de236b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Config: AndhraPradesh_Vishakapattanam\n",
      "Splits: ['train']\n",
      "Columns/features:\n",
      "  - audio: Audio(sampling_rate=None, decode=True, num_channels=None, stream_index=None)\n",
      "  - language: Value('string')\n",
      "  - speakerID: Value('float64')\n",
      "  - languagesKnown: Value('string')\n",
      "  - gender: Value('string')\n",
      "  - state: Value('string')\n",
      "  - district: Value('string')\n",
      "  - pincode: Value('int64')\n",
      "  - stay(years): Value('string')\n",
      "  - isTranscriptionAvailable: Value('string')\n",
      "  - transcript: Value('string')\n",
      "  - referenceImage: Value('string')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbc7724c2f29423880a406c4c3fd702b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db9fc3c840bf4f989cc80cd6bfb50d47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Config: ArunachalPradesh_Longding\n",
      "Splits: ['train']\n",
      "Columns/features:\n",
      "  - audio: Audio(sampling_rate=None, decode=True, num_channels=None, stream_index=None)\n",
      "  - language: Value('string')\n",
      "  - speakerID: Value('float64')\n",
      "  - languagesKnown: Value('string')\n",
      "  - gender: Value('string')\n",
      "  - state: Value('string')\n",
      "  - district: Value('string')\n",
      "  - pincode: Value('int64')\n",
      "  - stay(years): Value('string')\n",
      "  - isTranscriptionAvailable: Value('string')\n",
      "  - transcript: Value('string')\n",
      "  - referenceImage: Value('string')\n"
     ]
    }
   ],
   "source": [
    "inspect_hf_dataset(\"ARTPARK-IISc/Vaani\", max_configs=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05992cd",
   "metadata": {},
   "source": [
    "### Inspect ChildMandarin (columns + splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12f7de08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================================================\n",
      "DATASET: BAAI/ChildMandarin\n",
      "Configs (1): ['default'] \n",
      "\n",
      "--- Config: default\n",
      "Splits: ['train', 'validation', 'test']\n",
      "Columns/features:\n",
      "  - json: {'accent': Value('string'), 'age': Value('int64'), 'device': Value('string'), 'gender': Value('string'), 'id': Value('string'), 'location': Value('string'), 'speaker_id': Value('string'), 'text': Value('string')}\n",
      "  - wav: Audio(sampling_rate=None, decode=True, num_channels=None, stream_index=None)\n",
      "  - __key__: Value('string')\n",
      "  - __url__: Value('string')\n"
     ]
    }
   ],
   "source": [
    "inspect_hf_dataset(\"BAAI/ChildMandarin\", max_configs=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da70f26",
   "metadata": {},
   "source": [
    "### Inspect AudioSet WDS (file-based repo + splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83826f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================================================\n",
      "REPO FILE LIST: confit/audioset-16khz-wds\n",
      "Total files: 735\n",
      "  .gitattributes\n",
      "  20k/test/shard-00000.tar\n",
      "  20k/test/shard-00001.tar\n",
      "  20k/test/shard-00002.tar\n",
      "  20k/test/shard-00003.tar\n",
      "  20k/test/shard-00004.tar\n",
      "  20k/test/shard-00005.tar\n",
      "  20k/train/shard-00000.tar\n",
      "  20k/train/shard-00001.tar\n",
      "  20k/train/shard-00002.tar\n",
      "  20k/train/shard-00003.tar\n",
      "  20k/train/shard-00004.tar\n",
      "  20k/train/shard-00005.tar\n",
      "  20k/train/shard-00006.tar\n",
      "  2m/test/shard-00000.tar\n",
      "  2m/test/shard-00001.tar\n",
      "  2m/test/shard-00002.tar\n",
      "  2m/test/shard-00003.tar\n",
      "  2m/test/shard-00004.tar\n",
      "  2m/test/shard-00005.tar\n",
      "  2m/train/shard-00000.tar\n",
      "  2m/train/shard-00001.tar\n",
      "  2m/train/shard-00002.tar\n",
      "  2m/train/shard-00003.tar\n",
      "  2m/train/shard-00004.tar\n",
      "  2m/train/shard-00005.tar\n",
      "  2m/train/shard-00006.tar\n",
      "  2m/train/shard-00007.tar\n",
      "  2m/train/shard-00008.tar\n",
      "  2m/train/shard-00009.tar\n",
      "  2m/train/shard-00010.tar\n",
      "  2m/train/shard-00011.tar\n",
      "  2m/train/shard-00012.tar\n",
      "  2m/train/shard-00013.tar\n",
      "  2m/train/shard-00014.tar\n",
      "  2m/train/shard-00015.tar\n",
      "  2m/train/shard-00016.tar\n",
      "  2m/train/shard-00017.tar\n",
      "  2m/train/shard-00018.tar\n",
      "  2m/train/shard-00019.tar\n",
      "  2m/train/shard-00020.tar\n",
      "  2m/train/shard-00021.tar\n",
      "  2m/train/shard-00022.tar\n",
      "  2m/train/shard-00023.tar\n",
      "  2m/train/shard-00024.tar\n",
      "  2m/train/shard-00025.tar\n",
      "  2m/train/shard-00026.tar\n",
      "  2m/train/shard-00027.tar\n",
      "  2m/train/shard-00028.tar\n",
      "  2m/train/shard-00029.tar\n",
      "  2m/train/shard-00030.tar\n",
      "  2m/train/shard-00031.tar\n",
      "  2m/train/shard-00032.tar\n",
      "  2m/train/shard-00033.tar\n",
      "  2m/train/shard-00034.tar\n",
      "  2m/train/shard-00035.tar\n",
      "  2m/train/shard-00036.tar\n",
      "  2m/train/shard-00037.tar\n",
      "  2m/train/shard-00038.tar\n",
      "  2m/train/shard-00039.tar\n",
      "  2m/train/shard-00040.tar\n",
      "  2m/train/shard-00041.tar\n",
      "  2m/train/shard-00042.tar\n",
      "  2m/train/shard-00043.tar\n",
      "  2m/train/shard-00044.tar\n",
      "  2m/train/shard-00045.tar\n",
      "  2m/train/shard-00046.tar\n",
      "  2m/train/shard-00047.tar\n",
      "  2m/train/shard-00048.tar\n",
      "  2m/train/shard-00049.tar\n",
      "  2m/train/shard-00050.tar\n",
      "  2m/train/shard-00051.tar\n",
      "  2m/train/shard-00052.tar\n",
      "  2m/train/shard-00053.tar\n",
      "  2m/train/shard-00054.tar\n",
      "  2m/train/shard-00055.tar\n",
      "  2m/train/shard-00056.tar\n",
      "  2m/train/shard-00057.tar\n",
      "  2m/train/shard-00058.tar\n",
      "  2m/train/shard-00059.tar\n",
      " ...\n"
     ]
    }
   ],
   "source": [
    "inspect_repo_files(\"confit/audioset-16khz-wds\", repo_type=\"dataset\", max_files=80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61d4b928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0836c885ca8e44e9b9506cb2c3a384ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (incomplete total...): 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "647436ee1f1143dfa24cc029f43f558f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: /scratch/users/arunps/speaker-type-classifier/data_hf/raw/v1/audioset_wds_one\n",
      "Shard: /scratch/users/arunps/speaker-type-classifier/data_hf/raw/v1/audioset_wds_one/20k/train/shard-00000.tar\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path\n",
    "\n",
    "AUD_ROOT = Path(\"/scratch/users/arunps/speaker-type-classifier/data_hf/raw/v1/audioset_wds_one\")\n",
    "\n",
    "snapshot_download(\n",
    "    repo_id=\"confit/audioset-16khz-wds\",\n",
    "    repo_type=\"dataset\",\n",
    "    local_dir=str(AUD_ROOT),\n",
    "    allow_patterns=[\n",
    "        \"20k/train/shard-00000.tar\",\n",
    "        \"README.md\",\n",
    "        \"dataset_infos.json\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Saved to:\", AUD_ROOT)\n",
    "print(\"Shard:\", AUD_ROOT / \"20k/train/shard-00000.tar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "158c4a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "EXCLUDE_PATTERNS = [\n",
    "    r\"\\bspeech\\b\",\n",
    "    r\"\\btalking\\b\",\n",
    "    r\"\\bconversation\\b\",\n",
    "    r\"\\bwhisper(ing)?\\b\",\n",
    "    r\"\\bvocal(ization|ise|ize|)\\b\",\n",
    "    r\"\\bvoice\\b\",\n",
    "    r\"\\bsinging\\b\",\n",
    "    r\"\\bchoir\\b\",\n",
    "    r\"\\blaughter\\b\",\n",
    "    r\"\\bgiggle\\b\",\n",
    "    r\"\\bcry(ing)?\\b\",\n",
    "    r\"\\bbaby\\b\",\n",
    "    r\"\\binfant\\b\",\n",
    "    r\"\\bchild\\b\",\n",
    "    r\"\\bkid\\b\",\n",
    "    r\"\\btoddler\\b\",\n",
    "    r\"\\bbabble\\b\",\n",
    "]\n",
    "\n",
    "exclude_re = re.compile(\"|\".join(EXCLUDE_PATTERNS), re.IGNORECASE)\n",
    "\n",
    "def is_background_label_list(label_list):\n",
    "    text = \" | \".join([str(x) for x in label_list])\n",
    "    return exclude_re.search(text) is None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48214ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- sample 0 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "BACKGROUND → label (first 10): ['Clarinet'] ... len = 1\n",
      "\n",
      "--- sample 1 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "BACKGROUND → label (first 10): ['Tabla', 'Folk music', 'Music', 'Classical music', 'Flute'] ... len = 5\n",
      "\n",
      "--- sample 2 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "EXCLUDED → label (first 10): ['Singing', 'Music', 'Salsa music'] ... len = 3\n",
      "\n",
      "--- sample 3 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "BACKGROUND → label (first 10): ['Telephone'] ... len = 1\n",
      "\n",
      "--- sample 4 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "BACKGROUND → label (first 10): ['Brass instrument', 'Trumpet'] ... len = 2\n",
      "\n",
      "--- sample 5 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "BACKGROUND → label (first 10): ['Organ', 'Hammond organ'] ... len = 2\n",
      "\n",
      "--- sample 6 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "EXCLUDED → label (first 10): ['Giggle', 'Speech', 'Inside, small room'] ... len = 3\n",
      "\n",
      "--- sample 7 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "BACKGROUND → label (first 10): ['Bird flight, flapping wings'] ... len = 1\n",
      "\n",
      "--- sample 8 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "EXCLUDED → label (first 10): ['Slam', 'Speech'] ... len = 2\n",
      "\n",
      "--- sample 9 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "BACKGROUND → label (first 10): ['Guitar', 'Music', 'Electronic tuner'] ... len = 3\n",
      "\n",
      "--- sample 10 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "BACKGROUND → label (first 10): ['Doorbell', 'Music'] ... len = 2\n",
      "\n",
      "--- sample 11 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "BACKGROUND → label (first 10): ['Fart'] ... len = 1\n",
      "\n",
      "--- sample 12 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "EXCLUDED → label (first 10): ['Grunt', 'Speech'] ... len = 2\n",
      "\n",
      "--- sample 13 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "EXCLUDED → label (first 10): ['Clock', 'Speech'] ... len = 2\n",
      "\n",
      "--- sample 14 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "EXCLUDED → label (first 10): ['Singing', 'Bluegrass'] ... len = 2\n",
      "\n",
      "--- sample 15 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "BACKGROUND → label (first 10): ['Music', 'Reggae'] ... len = 2\n",
      "\n",
      "--- sample 16 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "EXCLUDED → label (first 10): ['Computer keyboard', 'Speech'] ... len = 2\n",
      "\n",
      "--- sample 17 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "BACKGROUND → label (first 10): ['Echo', 'Effects unit', 'Guitar', 'Music', 'Musical instrument', 'Plucked string instrument'] ... len = 6\n",
      "\n",
      "--- sample 18 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "BACKGROUND → label (first 10): ['Doorbell', 'Music'] ... len = 2\n",
      "\n",
      "--- sample 19 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "BACKGROUND → label (first 10): ['Music', 'Breaking'] ... len = 2\n",
      "\n",
      "--- sample 20 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "BACKGROUND → label (first 10): ['Music', 'Music for children'] ... len = 2\n",
      "\n",
      "--- sample 21 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "BACKGROUND → label (first 10): ['Wild animals', 'Animal'] ... len = 2\n",
      "\n",
      "--- sample 22 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "BACKGROUND → label (first 10): ['Silence', 'Single-lens reflex camera'] ... len = 2\n",
      "\n",
      "--- sample 23 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "BACKGROUND → label (first 10): ['Stomach rumble'] ... len = 1\n",
      "\n",
      "--- sample 24 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "EXCLUDED → label (first 10): ['Dial tone', 'Speech', 'Inside, small room'] ... len = 3\n",
      "\n",
      "--- sample 25 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "BACKGROUND → label (first 10): ['Motor vehicle (road)', 'Ice cream truck, ice cream van', 'Vehicle', 'Car'] ... len = 4\n",
      "\n",
      "--- sample 26 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "BACKGROUND → label (first 10): ['Coin (dropping)'] ... len = 1\n",
      "\n",
      "--- sample 27 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "BACKGROUND → label (first 10): ['Gunshot, gunfire', 'Machine gun'] ... len = 2\n",
      "\n",
      "--- sample 28 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "BACKGROUND → label (first 10): ['Hammer'] ... len = 1\n",
      "\n",
      "--- sample 29 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "EXCLUDED → label (first 10): ['Slam', 'Speech', 'Inside, large room or hall'] ... len = 3\n",
      "\n",
      "--- sample 30 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "BACKGROUND → label (first 10): ['Brass instrument', 'Wind instrument, woodwind instrument', 'Shofar'] ... len = 3\n",
      "\n",
      "--- sample 31 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "BACKGROUND → label (first 10): ['Environmental noise'] ... len = 1\n",
      "\n",
      "--- sample 32 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "EXCLUDED → label (first 10): ['Laughter', 'Gargling', 'Speech'] ... len = 3\n",
      "\n",
      "--- sample 33 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "BACKGROUND → label (first 10): ['Echo'] ... len = 1\n",
      "\n",
      "--- sample 34 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "BACKGROUND → label (first 10): ['Groan'] ... len = 1\n",
      "\n",
      "--- sample 35 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "BACKGROUND → label (first 10): ['Smoke detector, smoke alarm'] ... len = 1\n",
      "\n",
      "--- sample 36 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "EXCLUDED → label (first 10): ['Laughter', 'Bouncing', 'Speech'] ... len = 3\n",
      "\n",
      "--- sample 37 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "BACKGROUND → label (first 10): ['Music', 'Rhythm and blues'] ... len = 2\n",
      "\n",
      "--- sample 38 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "EXCLUDED → label (first 10): ['Singing', 'Music', 'Bang'] ... len = 3\n",
      "\n",
      "--- sample 39 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "BACKGROUND → label (first 10): ['Fowl', 'Goose'] ... len = 2\n",
      "\n",
      "--- sample 40 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "BACKGROUND → label (first 10): ['Siren', 'Civil defense siren'] ... len = 2\n",
      "\n",
      "--- sample 41 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "EXCLUDED → label (first 10): ['Splash, splatter', 'Water', 'Speech'] ... len = 3\n",
      "\n",
      "--- sample 42 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "BACKGROUND → label (first 10): ['Filing (rasp)', 'Rub'] ... len = 2\n",
      "\n",
      "--- sample 43 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "BACKGROUND → label (first 10): ['Music', 'Quack', 'Duck', 'Animal'] ... len = 4\n",
      "\n",
      "--- sample 44 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "BACKGROUND → label (first 10): ['Bus', 'Vehicle'] ... len = 2\n",
      "\n",
      "--- sample 45 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "BACKGROUND → label (first 10): ['Roar', 'Animal'] ... len = 2\n",
      "\n",
      "--- sample 46 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "EXCLUDED → label (first 10): ['Music', 'Music for children', 'Speech'] ... len = 3\n",
      "\n",
      "--- sample 47 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "BACKGROUND → label (first 10): ['Drum and bass', 'Music'] ... len = 2\n",
      "\n",
      "--- sample 48 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "EXCLUDED → label (first 10): ['Singing', 'Carnatic music', 'Music'] ... len = 3\n",
      "\n",
      "--- sample 49 keys: ['__key__', '__url__', 'wav', '__local_path__', 'json']\n",
      "json keys: ['id', 'label', 'label_id']\n",
      "BACKGROUND → label (first 10): ['Tabla', 'Percussion'] ... len = 2\n",
      "\n",
      "Summary\n",
      "Background candidates: 35\n",
      "Excluded (speech/child/etc): 15\n"
     ]
    }
   ],
   "source": [
    "import webdataset as wds\n",
    "import json\n",
    "from itertools import islice\n",
    "\n",
    "shard_path = str(AUD_ROOT / \"20k/train/shard-00000.tar\")\n",
    "ds = wds.WebDataset(shard_path).decode()\n",
    "\n",
    "bg = 0\n",
    "non_bg = 0\n",
    "\n",
    "for i, sample in enumerate(islice(ds, 50)):\n",
    "    print(f\"\\n--- sample {i} keys:\", list(sample.keys()))\n",
    "\n",
    "    raw = sample[\"json\"]\n",
    "\n",
    "    # raw can be dict OR bytes/str\n",
    "    if isinstance(raw, dict):\n",
    "        meta = raw\n",
    "    else:\n",
    "        if isinstance(raw, (bytes, bytearray)):\n",
    "            raw = raw.decode(\"utf-8\", errors=\"replace\")\n",
    "        meta = json.loads(raw)\n",
    "\n",
    "    print(\"json keys:\", list(meta.keys()))\n",
    "\n",
    "    labels = meta.get(\"label\") or meta.get(\"labels\") or []\n",
    "    if isinstance(labels, str):\n",
    "        labels = [labels]\n",
    "\n",
    "    if is_background_label_list(labels):\n",
    "        tag = \"BACKGROUND\"\n",
    "        bg += 1\n",
    "    else:\n",
    "        tag = \"EXCLUDED\"\n",
    "        non_bg += 1\n",
    "\n",
    "    print(f\"{tag} → label (first 10):\", labels[:10], \"... len =\", len(labels))\n",
    "\n",
    "print(\"\\nSummary\")\n",
    "print(\"Background candidates:\", bg)\n",
    "print(\"Excluded (speech/child/etc):\", non_bg)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speaker-type-classifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
